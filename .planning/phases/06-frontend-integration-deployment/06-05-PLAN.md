---
phase: 06-frontend-integration-deployment
plan: 05
type: execute
wave: 3
depends_on: ["06-01", "06-02", "06-03", "06-04"]
files_modified:
  - README.md
  - docs/ARCHITECTURE.md
  - docs/DEPLOYMENT.md
  - docs/PIPELINE_DESIGN.md
  - docs/EXAMPLE_QUERIES.md
  - CONTRIBUTING.md
  - LICENSE
autonomous: true

must_haves:
  truths:
    - "README.md explains project overview, features, and quickstart"
    - "ARCHITECTURE.md describes system components and data flow"
    - "DEPLOYMENT.md provides local and cloud deployment instructions"
    - "PIPELINE_DESIGN.md explains RAG pipeline, chunking, and KG usage"
    - "EXAMPLE_QUERIES.md provides 3+ Q&A examples with commentary"
    - "CONTRIBUTING.md outlines development guidelines"
    - "LICENSE file contains MIT license"
  artifacts:
    - path: "README.md"
      provides: "Project overview and quickstart"
      contains: "IRONMIND"
    - path: "docs/ARCHITECTURE.md"
      provides: "System architecture documentation"
      contains: "RAG"
    - path: "docs/DEPLOYMENT.md"
      provides: "Deployment instructions"
      contains: "docker-compose"
    - path: "docs/PIPELINE_DESIGN.md"
      provides: "RAG pipeline explanation"
      contains: "hybrid retrieval"
    - path: "LICENSE"
      provides: "MIT license"
      contains: "MIT License"
  key_links: []
---

<objective>
Create comprehensive project documentation for monorepo

Purpose: Enable new developers and evaluators to understand, run, and contribute to IRONMIND
Output: Complete documentation suite: README, ARCHITECTURE, DEPLOYMENT, PIPELINE_DESIGN, EXAMPLE_QUERIES, CONTRIBUTING, LICENSE
</objective>

<execution_context>
@C:\Users\Omer\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\Omer\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/REQUIREMENTS.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create README.md with overview and quickstart</name>
  <files>README.md</files>
  <action>
Create `README.md` in project root:

```markdown
# IRONMIND

Technical Document Intelligence for Aerospace & Defense

IRONMIND is a RAG (Retrieval-Augmented Generation) system designed for technical documentation analysis. It enables users to upload technical documents and receive AI-powered answers with transparent source citations.

## Features

- **Document Upload**: Support for PDF and DOCX documents (up to 10 per user)
- **Hybrid Retrieval**: Semantic search + BM25 keyword matching with RRF fusion
- **Knowledge Graph**: Entity and relationship extraction for technical components
- **Multi-Source Synthesis**: Cross-document reasoning with citation aggregation
- **Source Traceability**: Every answer includes inline citations with page references
- **IAI Branding**: Custom interface for Israel Aerospace Industries evaluation

## Tech Stack

| Component | Technology |
|-----------|------------|
| Frontend | Next.js 16, React 19, Tailwind CSS, Better Auth |
| Backend | FastAPI, Python 3.11 |
| Vector Search | txtai with OpenAI embeddings |
| Graph Database | FalkorDB |
| Document Processing | Docling |
| LLM | OpenAI GPT-5-mini |
| Reranking | DeepInfra Qwen3-Reranker |
| Deployment | Docker Compose, Caddy (HTTPS) |

## Quickstart

### Prerequisites

- Docker & Docker Compose
- OpenAI API key
- DeepInfra API key (for reranking)

### Local Development

1. Clone the repository:
   ```bash
   git clone <repository-url>
   cd ironmind
   ```

2. Copy environment template:
   ```bash
   cp .env.example .env
   # Edit .env with your API keys
   ```

3. Start services:
   ```bash
   docker-compose up -d
   ```

4. Access the application:
   - Frontend: http://localhost:3000
   - Backend API: http://localhost:8000
   - API Docs: http://localhost:8000/docs

### Production Deployment

See [docs/DEPLOYMENT.md](docs/DEPLOYMENT.md) for Hetzner VPS deployment instructions.

## Project Structure

```
ironmind/
├── frontend/           # Next.js frontend application
│   ├── app/           # App router pages
│   ├── components/    # Shared React components
│   └── lib/           # Utilities and API client
├── backend/           # FastAPI backend application
│   ├── app/
│   │   ├── routers/   # API endpoints
│   │   ├── services/  # Business logic
│   │   ├── models/    # Pydantic schemas
│   │   └── core/      # Database, logging
├── infra/             # Infrastructure configuration
│   ├── docker-compose.prod.yml
│   └── Caddyfile
├── docs/              # Documentation
│   ├── ARCHITECTURE.md
│   ├── DEPLOYMENT.md
│   ├── PIPELINE_DESIGN.md
│   └── EXAMPLE_QUERIES.md
└── docker-compose.yml # Local development
```

## Documentation

- [Architecture Overview](docs/ARCHITECTURE.md) - System components and data flow
- [Deployment Guide](docs/DEPLOYMENT.md) - Local and production setup
- [Pipeline Design](docs/PIPELINE_DESIGN.md) - RAG pipeline, chunking, knowledge graph
- [Example Queries](docs/EXAMPLE_QUERIES.md) - Sample Q&A with explanations

## API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/documents/upload` | POST | Upload a document |
| `/api/documents` | GET | List user's documents |
| `/api/documents/{id}/status` | GET | Get processing status |
| `/api/chat` | POST | Ask a question |
| `/health` | GET | Service health check |

## License

MIT License - see [LICENSE](LICENSE)

## Acknowledgments

- Built for Israel Aerospace Industries (IAI) POC evaluation
- Powered by OpenAI, DeepInfra, and open-source RAG technologies

---

**Note**: This is a Proof of Concept system. Not intended for production use with classified or sensitive data.
```
  </action>
  <verify>README.md exists and contains overview, quickstart, and structure</verify>
  <done>README.md with project overview, features, quickstart, and structure</done>
</task>

<task type="auto">
  <name>Task 2: Create core documentation files</name>
  <files>docs/ARCHITECTURE.md, docs/DEPLOYMENT.md, docs/PIPELINE_DESIGN.md</files>
  <action>
1. Create `docs/ARCHITECTURE.md`:

```markdown
# IRONMIND Architecture

## Overview

IRONMIND is a RAG (Retrieval-Augmented Generation) system for technical document analysis. This document describes the system architecture, components, and data flow.

## System Components

```
┌─────────────────────────────────────────────────────────────────────┐
│                           User Interface                             │
│  ┌────────────┐  ┌────────────────┐  ┌────────────────────────┐    │
│  │  Landing   │  │   Dashboard    │  │    Chat Interface      │    │
│  │   Page     │  │ (Upload/List)  │  │  (Q&A with Citations)  │    │
│  └────────────┘  └────────────────┘  └────────────────────────┘    │
└────────────────────────────────────────────────────────────────────┘
                                │
                          Better Auth
                                │
                                ▼
┌─────────────────────────────────────────────────────────────────────┐
│                         Backend API (FastAPI)                        │
│  ┌──────────┐  ┌────────────────┐  ┌───────────────────────────┐  │
│  │ Document │  │  Chat          │  │  Debug Endpoints          │  │
│  │ Router   │  │  Router        │  │  (Graph inspection)       │  │
│  └────┬─────┘  └───────┬────────┘  └───────────────────────────┘  │
│       │                │                                            │
│  ┌────▼────────────────▼────────────────────────────────────────┐  │
│  │                    Service Layer                              │  │
│  │  ┌─────────┐  ┌──────────┐  ┌─────────┐  ┌──────────────┐   │  │
│  │  │Pipeline │  │Retriever │  │Reranker │  │  Generator   │   │  │
│  │  └────┬────┘  └────┬─────┘  └────┬────┘  └──────┬───────┘   │  │
│  └───────┼────────────┼─────────────┼───────────────┼───────────┘  │
└──────────┼────────────┼─────────────┼───────────────┼──────────────┘
           │            │             │               │
           ▼            ▼             ▼               ▼
┌──────────────┐  ┌──────────┐  ┌──────────┐  ┌────────────┐
│   Docling    │  │  txtai   │  │DeepInfra │  │  OpenAI    │
│   (Parsing)  │  │ (Index)  │  │(Rerank)  │  │ (LLM+Embed)│
└──────────────┘  └──────────┘  └──────────┘  └────────────┘
                       │
                       ▼
                ┌──────────────┐
                │  FalkorDB    │
                │   (Graph)    │
                └──────────────┘
```

## Data Flow

### Document Ingestion

1. **Upload**: User uploads PDF/DOCX via frontend
2. **Parse**: Docling extracts structured content (sections, headings, pages)
3. **Chunk**: Semantic chunking preserves context boundaries (~1000 tokens)
4. **Extract**: LLM extracts entities and relationships for knowledge graph
5. **Index**: Chunks indexed in txtai with OpenAI embeddings
6. **Store**: Graph stored in FalkorDB, metadata in SQLite

### Query Processing

1. **Retrieve**: Hybrid search (semantic + BM25) returns top-25 chunks
2. **Expand**: Document relationships add related document chunks
3. **Rerank**: Cross-encoder reranks to top-12
4. **Generate**: GPT-5-mini generates answer with citations from top-10

## Component Details

### Frontend (Next.js 16)

- **Better Auth**: Session management with SQLite backend
- **App Router**: Server components for SEO, client components for interactivity
- **API Client**: Token exchange for backend authentication

### Backend (FastAPI)

- **Routers**: documents, chat, health, debug
- **Services**: Pipeline, Retriever, Reranker, Generator
- **Middleware**: CORS, Request ID correlation, JWT validation

### External Services

| Service | Purpose | Model |
|---------|---------|-------|
| Docling | Document parsing | docling-serve v1.10.0 |
| OpenAI | Embeddings | text-embedding-3-small |
| OpenAI | Generation | gpt-5-mini |
| DeepInfra | Reranking | Qwen3-Reranker-0.6B |
| FalkorDB | Graph storage | Latest |

## Security

- JWT tokens for API authentication (15-min expiry)
- Non-root Docker users
- CORS origin validation
- Input validation on all endpoints
- No secrets in client bundles

## Scalability Considerations

Current POC design (2-3 users, 10 docs each):

- Single backend instance with Gunicorn (4 workers)
- SQLite for auth and document metadata
- txtai with file-based index

For scaling beyond POC:
- Postgres for metadata
- Redis for caching
- Distributed task queue for processing
- Horizontal backend scaling
```

2. Create `docs/DEPLOYMENT.md`:

```markdown
# IRONMIND Deployment Guide

## Local Development

### Prerequisites

- Docker Desktop 4.x+
- Node.js 20+ (for frontend development)
- Python 3.11+ (for backend development)

### Quick Start

```bash
# Clone repository
git clone <repository-url>
cd ironmind

# Copy environment template
cp .env.example .env

# Edit .env with your API keys:
# - OPENAI_API_KEY
# - DEEPINFRA_API_KEY
# - AUTH_SECRET (generate with: openssl rand -hex 32)

# Start all services
docker-compose up -d

# Check service health
docker-compose ps
```

### Development Mode

For hot-reload during development:

```bash
# Terminal 1: Backend with auto-reload
cd backend
pip install -r requirements.txt
uvicorn app.main:app --reload --port 8000

# Terminal 2: Frontend with hot-reload
cd frontend
npm install
npm run dev

# Terminal 3: Supporting services
docker-compose up falkordb docling
```

### Environment Variables

| Variable | Required | Description |
|----------|----------|-------------|
| `OPENAI_API_KEY` | Yes | OpenAI API key for embeddings and generation |
| `DEEPINFRA_API_KEY` | Yes | DeepInfra key for Qwen reranker |
| `AUTH_SECRET` | Yes | JWT secret (32+ hex chars) |
| `CORS_ORIGINS` | No | Allowed origins (default: localhost:3000) |
| `LOG_LEVEL` | No | Logging level (default: INFO) |

## Production Deployment (Hetzner VPS)

### Server Requirements

- Hetzner CX21 or CX31 (2 vCPU, 4-8GB RAM)
- Ubuntu 22.04 LTS
- Docker & Docker Compose installed
- Domain with DNS configured

### Initial Setup

```bash
# SSH into server
ssh root@your-server-ip

# Install Docker
curl -fsSL https://get.docker.com | sh
apt install docker-compose-plugin

# Create deployment user
useradd -m -s /bin/bash deploy
usermod -aG docker deploy

# Clone repository
su - deploy
git clone <repository-url>
cd ironmind
```

### Configuration

```bash
# Copy production environment template
cp infra/.env.production.example infra/.env.production

# Edit production config
nano infra/.env.production
```

Required settings:
- `DOMAIN`: Your domain (e.g., ironmind.example.com)
- `NEXT_PUBLIC_APP_URL`: https://ironmind.example.com
- `NEXT_PUBLIC_API_URL`: https://api.ironmind.example.com
- `CORS_ORIGINS`: https://ironmind.example.com
- API keys for OpenAI and DeepInfra

### Deploy

```bash
# Build and start production stack
cd infra
docker compose -f docker-compose.prod.yml --env-file .env.production up -d --build

# Verify services
docker compose -f docker-compose.prod.yml ps

# Check logs
docker compose -f docker-compose.prod.yml logs -f
```

### SSL Certificates

Caddy automatically obtains Let's Encrypt certificates. Ensure:
- Port 80 and 443 are open in firewall
- DNS A records point to server IP
- `caddy_data` volume persists (never delete)

### Updates

```bash
# Pull latest code
git pull origin main

# Rebuild and restart
docker compose -f docker-compose.prod.yml up -d --build

# Zero-downtime: new containers start before old ones stop
```

### Monitoring

```bash
# View logs
docker compose -f docker-compose.prod.yml logs -f backend

# Check resource usage
docker stats

# Health check
curl https://your-domain.com/health
```

### Backup

```bash
# Backup volumes
docker run --rm -v ironmind_backend-data:/data -v $(pwd):/backup alpine tar cvf /backup/backend-data.tar /data
docker run --rm -v ironmind_falkordb-data:/data -v $(pwd):/backup alpine tar cvf /backup/falkordb-data.tar /data
```

## Troubleshooting

### Common Issues

**Frontend can't reach backend**
- Check CORS_ORIGINS includes frontend domain
- Verify Caddyfile routes correctly
- Check backend health: `curl http://localhost:8000/health`

**SSL certificate issues**
- Ensure ports 80/443 are open
- Check DNS propagation: `dig your-domain.com`
- View Caddy logs: `docker logs ironmind-caddy-1`

**Document processing stuck**
- Check Docling health: `curl http://localhost:5001/health`
- Increase Docling memory if OOM
- View processing logs in backend

**Out of memory**
- Docling uses ~2GB for large PDFs
- Consider CX31 (8GB RAM) for production
- Limit concurrent document processing
```

3. Create `docs/PIPELINE_DESIGN.md`:

```markdown
# IRONMIND Pipeline Design

## Overview

IRONMIND uses a multi-stage RAG pipeline optimized for technical documentation:

1. **Document Processing** - Parse, chunk, extract entities
2. **Hybrid Retrieval** - Semantic + keyword search with RRF fusion
3. **Graph Enhancement** - Entity relationships and document links
4. **Reranking** - Cross-encoder precision boost
5. **Generation** - Grounded answer synthesis with citations

## Document Processing Pipeline

### Stage 1: Parsing (Docling)

Docling extracts structured content preserving:
- Section headings and hierarchy
- Page numbers and boundaries
- Tables and lists
- Inline formatting

Output: Markdown with metadata annotations

### Stage 2: Semantic Chunking

Unlike fixed-size chunking, semantic chunking:
- Respects section boundaries (never splits mid-section)
- Targets ~1000 tokens per chunk with 15% overlap
- Merges small sections (<50 tokens)
- Splits large sections at paragraph boundaries

Chunk metadata includes:
- doc_id, user_id (isolation)
- page_range, section_title (traceability)
- SHA-256 hash (deduplication)

### Stage 3: Entity Extraction

LLM (GPT-4o with Structured Outputs) extracts:

**Entity Types:**
- hardware, software, configuration, error

**Relationship Types:**
- depends_on, configures, connects_to, is_part_of

Extraction uses schema-constrained generation for 100% valid output.

### Stage 4: Document Relationships

Cross-reference detection finds document links:

**Explicit Citations:**
- Document code patterns (e.g., "FC-001-234")
- "See Document X" patterns
- Section references

**Shared Entities:**
- Documents sharing 2+ entities are linked
- Strength based on entity count (0.5 - 0.9)

### Stage 5: Indexing

txtai index with:
- OpenAI text-embedding-3-small embeddings
- BM25 sparse index for keyword matching
- SQLite backend for persistence
- User-based filtering for multi-tenancy

## Query Processing Pipeline

### Stage 1: Hybrid Retrieval

**Semantic Search:**
- Query embedded with same model (text-embedding-3-small)
- Cosine similarity against indexed chunks
- Returns top-25 by score

**BM25 Search:**
- Keyword matching with TF-IDF weighting
- Good for technical terms, acronyms, codes
- Returns top-25 by score

**Reciprocal Rank Fusion (RRF):**
```
score(d) = Σ 1/(k + rank_i(d))
```
Where k=60 (standard), combining both result sets.

### Stage 2: Graph Enhancement

For relationship queries (detected via keywords like "connect", "depend"):

1. Extract entities from query
2. Retrieve related entities from graph (depth=2)
3. Fetch chunks mentioning those entities
4. Merge with semantic results (deduplicated)

### Stage 3: Document Expansion

If related documents exist (via cross-references):

1. Find top-2 related docs (min_strength=0.5)
2. Retrieve additional chunks from related docs
3. Merge into result set

### Stage 4: Reranking

DeepInfra Qwen3-Reranker-0.6B:
- Cross-encoder scores query-document pairs
- More accurate than bi-encoder similarity
- 30-50% precision improvement
- Returns top-12

### Stage 5: Generation

GPT-5-mini with grounding prompt:

**System Prompt:**
- Answer ONLY from provided documents
- Use [N] citations inline
- Acknowledge uncertainty
- For multi-source: organize by topic, note consensus/disagreement

**Context Format:**
```
[1: filename.docx, p.12-14]
<chunk text>

[2: filename.docx, p.23]
<chunk text>
```

**Multi-Source Synthesis:**
Activated when:
- 2+ documents in context
- 2+ chunks per document

Uses topic-organized prompting for cross-document patterns.

## Performance Characteristics

| Stage | Typical Latency | Notes |
|-------|-----------------|-------|
| Retrieval | 50-100ms | txtai + BM25 fusion |
| Expansion | 20-50ms | Graph queries |
| Reranking | 100-200ms | DeepInfra API call |
| Generation | 500-2000ms | OpenAI API call |
| **Total** | **1-3 seconds** | Target: <10s |

## Quality Metrics

- **Retrieval**: Recall@25 (are relevant docs retrieved?)
- **Reranking**: Precision@10 (are top results relevant?)
- **Generation**: Faithfulness (answers grounded in sources?)
- **Citations**: Traceability (can user verify claims?)

## Configuration

Key settings in `backend/app/config.py`:

```python
RETRIEVAL_LIMIT = 25      # Initial retrieval
RERANK_LIMIT = 12         # After reranking
CONTEXT_LIMIT = 10        # Sent to LLM
HYBRID_WEIGHT = 0.5       # Semantic vs BM25
MIN_SIMILARITY = 0.5      # Score threshold
```
```
  </action>
  <verify>All three documentation files exist with appropriate content</verify>
  <done>ARCHITECTURE.md, DEPLOYMENT.md, and PIPELINE_DESIGN.md created</done>
</task>

<task type="auto">
  <name>Task 3: Create remaining documentation files</name>
  <files>docs/EXAMPLE_QUERIES.md, CONTRIBUTING.md, LICENSE</files>
  <action>
1. Create `docs/EXAMPLE_QUERIES.md`:

```markdown
# IRONMIND Example Queries

This document provides example queries demonstrating IRONMIND's capabilities with technical documentation.

## Example 1: Basic Information Retrieval

**Query:** "What are the primary network layers described in the system architecture?"

**Expected Answer:**
> The system architecture consists of three primary network layers [1]:
> 1. Edge Layer - handles device connectivity
> 2. Core Layer - manages data routing
> 3. Management Layer - provides monitoring and control
>
> [1] FC-001-System-Architecture.docx, p.12-14

**Why it works:**
- Hybrid retrieval finds chunks mentioning "network layers" and "architecture"
- Reranking prioritizes the most relevant section
- Citation provides exact source for verification

---

## Example 2: Multi-Document Synthesis

**Query:** "How do the power system and navigation module interact according to the documentation?"

**Expected Answer:**
> Based on multiple documents, the power system and navigation module interact through:
>
> **Power Supply Interface [1]:**
> The navigation module requires 28V DC from the primary power bus...
>
> **Data Communication [2]:**
> Navigation data is transmitted via MIL-STD-1553 bus to the power management unit...
>
> Both documents confirm the critical dependency on stable power for navigation accuracy [1,2].
>
> [1] FC-020-Power-System.docx, p.8
> [2] FC-035-Navigation-Module.docx, p.15

**Why it works:**
- Multi-source synthesis detected (2+ documents)
- Topic-organized response groups related information
- Citations indicate which source supports each claim

---

## Example 3: Knowledge Graph Query

**Query:** "What components depend on the main controller?"

**Expected Answer:**
> Based on the documentation and component relationships [1,2]:
>
> The following components depend on the main controller:
> - Sensor Array (data processing dependency)
> - Display Unit (command interface)
> - Communication Module (timing synchronization)
>
> The main controller provides the central coordination point for all subsystem operations [1].
>
> [1] FC-001-System-Architecture.docx, p.23
> [2] Knowledge Graph - Main Controller

**Why it works:**
- Graph retrieval finds entities with "depends_on" relationships
- Combines document chunks with graph-derived knowledge
- Citation [2] transparently indicates graph-sourced information

---

## Example 4: Troubleshooting Query

**Query:** "What error codes indicate a sensor calibration failure?"

**Expected Answer:**
> According to the error code reference [1], sensor calibration failures are indicated by:
>
> | Code | Description |
> |------|-------------|
> | E-CAL-001 | Calibration timeout |
> | E-CAL-002 | Reference signal out of range |
> | E-CAL-003 | Sensor drift exceeds threshold |
>
> Recommended resolution: Follow the recalibration procedure in Section 5.3 [1].
>
> [1] FC-050-Maintenance-Guide.docx, p.45-46

**Why it works:**
- BM25 component excels at finding specific codes/terms
- Hybrid retrieval ensures both semantic and keyword matches
- Structured information (tables) preserved from source

---

## Example 5: Handling Unknown Information

**Query:** "What is the operating temperature range for the XYZ-9000 module?"

**Expected Answer:**
> I couldn't find specific information about the "XYZ-9000 module" in your uploaded documents.
>
> The available documentation covers the following modules:
> - ABC Controller (FC-001)
> - Navigation Unit (FC-035)
> - Power System (FC-020)
>
> Please check if this component is documented under a different name, or upload the relevant specification document.

**Why it works:**
- System acknowledges lack of information rather than hallucinating
- Provides helpful context about available documents
- Suggests actionable next steps

---

## Query Tips

1. **Be specific:** "power consumption of the navigation module" > "power stuff"
2. **Use technical terms:** System handles acronyms and codes well
3. **Ask about relationships:** "How does X connect to Y?" leverages knowledge graph
4. **Multi-document questions:** System synthesizes across all your uploaded docs

## Limitations

- Answers only from uploaded documents (no external knowledge)
- Complex multi-hop reasoning may require multiple queries
- Very large documents (100+ pages) may have retrieval gaps
- Scanned PDFs with poor OCR quality affect accuracy
```

2. Create `CONTRIBUTING.md` in project root:

```markdown
# Contributing to IRONMIND

Thank you for your interest in contributing to IRONMIND!

## Development Setup

### Prerequisites

- Docker & Docker Compose
- Node.js 20+
- Python 3.11+
- Git

### Local Development

1. Fork and clone the repository
2. Copy `.env.example` to `.env` and add your API keys
3. Start supporting services:
   ```bash
   docker-compose up falkordb docling -d
   ```
4. Start backend:
   ```bash
   cd backend
   pip install -r requirements.txt
   uvicorn app.main:app --reload
   ```
5. Start frontend:
   ```bash
   cd frontend
   npm install
   npm run dev
   ```

## Code Style

### Python (Backend)

- Follow PEP 8
- Use type hints for all functions
- Format with Black: `black app/`
- Lint with Ruff: `ruff check app/`
- Use Pydantic for data validation

### TypeScript (Frontend)

- Use TypeScript strict mode
- Format with Prettier
- Lint with ESLint: `npm run lint`
- Use functional components with hooks

## Testing

### Backend

```bash
cd backend
pytest tests/ -v
```

### Frontend

```bash
cd frontend
npm run test
```

## Pull Request Process

1. Create a feature branch: `git checkout -b feature/your-feature`
2. Make your changes with clear commit messages
3. Ensure tests pass
4. Update documentation if needed
5. Submit PR with description of changes

## Commit Messages

Follow conventional commits:
- `feat:` New feature
- `fix:` Bug fix
- `docs:` Documentation
- `refactor:` Code refactoring
- `test:` Adding tests

Example: `feat: add document deletion endpoint`

## Project Structure

```
ironmind/
├── frontend/       # Next.js application
├── backend/        # FastAPI application
├── infra/          # Deployment configuration
├── docs/           # Documentation
└── .planning/      # Project planning (not for PRs)
```

## Questions?

Open an issue for questions or discussions about contributing.
```

3. Create `LICENSE` in project root:

```
MIT License

Copyright (c) 2026 IRONMIND Contributors

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```
  </action>
  <verify>All documentation files exist: README.md, docs/ARCHITECTURE.md, docs/DEPLOYMENT.md, docs/PIPELINE_DESIGN.md, docs/EXAMPLE_QUERIES.md, CONTRIBUTING.md, LICENSE</verify>
  <done>Complete documentation suite created</done>
</task>

</tasks>

<verification>
1. Verify all files exist:
   ```bash
   ls -la README.md CONTRIBUTING.md LICENSE
   ls -la docs/
   ```
2. Check README renders correctly (preview in editor)
3. Verify no placeholder text remaining in any file
4. Ensure all links in README point to existing files
</verification>

<success_criteria>
- DOCS-01 COMPLETE: README.md with overview, features, tech stack, quickstart
- DOCS-02 COMPLETE: docs/ARCHITECTURE.md describes components and data flow
- DOCS-03 COMPLETE: docs/DEPLOYMENT.md provides local + cloud instructions
- DOCS-04 COMPLETE: docs/PIPELINE_DESIGN.md explains RAG pipeline and KG
- DOCS-05 COMPLETE: docs/EXAMPLE_QUERIES.md provides 5 Q&A examples
- DOCS-06 COMPLETE: CONTRIBUTING.md outlines development guidelines
- DOCS-07 COMPLETE: MIT LICENSE file
- DOCS-08 PARTIAL: Monorepo structure documented (actual structure already exists)
</success_criteria>

<output>
After completion, create `.planning/phases/06-frontend-integration-deployment/06-05-SUMMARY.md`
</output>
