# FastAPI and server
fastapi[standard]>=0.109.0
uvicorn[standard]>=0.27.0
gunicorn>=21.0.0

# Configuration
pydantic-settings>=2.0.0
python-dotenv>=1.0.0

# Logging
structlog>=24.1.0
asgi-correlation-id>=4.3.0

# Authentication
pyjwt>=2.8.0

# Database
aiosqlite>=0.19.0

# File operations
aiofiles>=23.2.0

# Text processing and chunking
tiktoken>=0.5.0
chonkie[semantic]>=1.5.4  # Production-grade hybrid chunking with semantic support

# RAG and embeddings (CPU-only, no CUDA dependencies)
# Install CPU-only torch first to avoid CUDA downloads
--extra-index-url https://download.pytorch.org/whl/cpu
torch>=2.4
txtai>=7.0.0
sqlite-vec>=0.1.0  # ANN support for txtai

# HTTP client with retry
httpx>=0.25.0
backoff>=2.2.0

# LLM and API clients
litellm>=1.0.0  # For DeepInfra reranker API
openai>=1.0.0  # For embeddings + LLM
redis>=5.0.0  # Optional, for caching

# Knowledge Graph
falkordb>=1.4.0  # Graph database Python client

# Multi-source synthesis (Phase 5)
python-Levenshtein>=0.25.0  # Fast fuzzy string matching for citation detection
networkx>=3.0  # Graph algorithms for document relationship scoring
